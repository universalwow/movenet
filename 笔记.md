# 关节点顺序
[nose, left eye, right eye, left ear, right ear,
left shoulder, right shoulder, left elbow, right elbow, left wrist,
right wrist, left hip, right hip, left knee, right knee,
left ankle, right ankle]

# 执行命令

## 项目中单人示例
python3.8 demo.py single_pose --dataset active --arch movenet --gpus -1 --debug 1 --load_model ../models/movenet.pth --demo ../images/two_pose.jpeg
## 根据项目中代码指示补全的多人示例
python3.8 demo.py multi_pose --dataset active --arch movenet --gpus -1 --debug 1 --load_model ../exp/multi_pose/yoga_movenet/model_best.pth --demo ../images/two_pose.jpeg

## 单人训练
python3.8 main.py single_pose --exp_id yoga_movenet --dataset active --arch movenet --batch_size 8  --lr 5e-4 --gpus -1 --num_epochs 10 --lr_step 30 --num_workers 0 --load_model ../models/movenet.pth
## 多人训练
python3.8 main.py multi_pose --exp_id yoga_movenet --dataset active --arch movenet --batch_size 8  --lr 5e-4 --gpus -1 --num_epochs 200 --lr_step 30 --num_workers 0 --load_model ../models/movenet.pth

# 基于单人改进的多人训练及多人示例
python3.8 main_multi.py single_pose --exp_id yoga_movenet --dataset active --arch movenet --batch_size 8  --lr 5e-4 --gpus -1 --num_epochs 10 --lr_step 30 --num_workers 0 --load_model ../models/movenet.pth
python3.8 demo_multi.py single_pose --dataset active --arch movenet --gpus -1 --debug 1 --load_model ../exp/single_pose/yoga_movenet/model_best.pth --demo ../images/two_pose.jpeg
python3.8 demo_multi.py single_pose --dataset active --arch movenet --gpus -1 --debug 1 --load_model ../models/movenet.pth --demo ../images/two_pose.jpeg

# 问题列表 以及 启示

1. 多人关节点topK逻辑，需要基于回归点取出， 再进行二次组装。现行的逻辑是先直接取出，再进行距离回归组装。
2. 根据sample 文件指示，hp_offset 取值范围应为0 - 1。
3. reg同上。
4. 基于边界框'二次组装'关节点的mask逻辑，应在边界框回归到理想可用状态时启用
5. 以上 2，3 点可以考虑放于模型训练内部。也可以用作后处理。应增加其训练权重
6. 基于中心点的边界回归需要更加良好的近场景数据集进行验证。基于coco筛选出的双人数据效果不佳。